
\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)
\usepackage{amsmath,amssymb}
\usepackage{bm}
\usepackage{natbib}

\newcommand{\EE}{\mathbb{E}}
\newcommand{\pp}{e(\bm{X})}
\newcommand{\ppi}{e(\bm{X_i})}
\newcommand{\hpp}{\hat{e}(\bm{X})}
\newcommand{\hppi}{\hat{e}(\bm{X_i})}

\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

\title{MOM PS Estimator under Strong Monotonicity}

\begin{document}
\maketitle

Say members of the control group of an RCT have no access to the treatment, but among the treatment group there are compliers and non-compliers---i.e. one-sided non-compliance.
(Of course, this could be, e.g., compliance in two different ways, etc.)
Then there are two principal strata $S$, never-takers and compliers. 
Say the exclusion restriction doesn't hold. 

\citet{feller2017principal} and \citet{dingLu} and others discuss estimating principal effects in one-sided noncompliance (which they call ``strong monotonicity'') under the assumption of principal ignorability, viz. $Y_C\independent S |\bm{X}$.
This has two problems, to my mind:
\begin{enumerate}
\item Sometimes principal ignorability is not plausible
\item If you assume the principal ignorability for $Y_T$ (``strong'' principal ignorability) then, as \citet{feller2017principal} points out, the principal effects conditional on covariates are equal to the ITT conditional on covariates---the stratum plays no role. But sometimes the role of the strata is what we're trying to estimate!
\end{enumerate}

The approach here takes a different tack, based on a different assumption which is maybe even less plausible---but which, I think, can be relaxed.

\section{Setup}
Estimating $\EE[Y_T|S]$ is straightforward, so for the remainder 
just consider the ``control'' group, $Z=0$, with $n$ (control) subjects and drop the $C$ subscript. 
The control group is a mixture of compliers and never-takers.

For subject $i$, $i=1,\dots,n$, we have:
\begin{itemize}
\item $Y_i$ observed outcome
\item $S_i \in \{0,1\}$ unobserved stratum
\item $\ppi=Pr(S_i=1|\bm{X}_i)$ %take as given (like, estimated from
  % treatment group)
\item $\hppi$ is an estimate of $\ppi$ from a separate sample
  (treatment group?) with $\EE[\hppi|\ppi]=\ppi$
\end{itemize}

Let $\mu_0=\EE[Y|S=0]$ and $\mu_1=\EE[Y|S=1]$.
The goal is to estimate $\mu_0$ and $\mu_1$.

\textbf{Assumption:}\\
\begin{equation}\label{eq:assumption}
\EE[Y_i|\bm{X}_i,S_i]=\EE[Y_i|S_i]=\mu_0\text{ or }\mu_1
\end{equation}
i.e. $Y$ is mean-independent of $\bm{X}$ conditional on $S$. 
This is problematic---why should $S$ contain all information about $Y$?

Note, it is kinda related to ``principal ignorability`` of \citet{feller2017principal} and \citet{dingLu}, $Y\independent S |\bm{X}_i$ but, obviously, different too. 


\section{M-Estimator}
As a preliminary, note that
\begin{align*}
  \EE[S|\hpp]&=\EE\left\{\EE[S|\pp,\hpp]|\hpp\right\}\\
             &=\EE\left\{\EE[S|\pp]|\hpp\right\}\\
             &=\EE[\pp|\hpp]=\hpp
\end{align*}

Then, note
\begin{align*}
  \EE[Y|\hpp]&=\EE\left\{\EE[Y|\hpp,S]|\hpp\right\}\\
             &=\EE\left\{\EE[Y|S]|\hpp\right\}\\
             &=\EE[\mu_1S+\mu_0(1-S)|\hpp]\\
             &=\mu_1\hpp+\mu_0(1-\hpp)
\end{align*}

Then we have
\begin{equation*}
  \EE[Y]=\EE\EE[Y|\hpp]=\mu_1\EE\hpp+\mu_0(1-\EE\hpp)
\end{equation*}

Next we have

\begin{align*}
  \EE[Y\hpp]&=\EE\left\{\EE[Y\hpp|\hpp]\right\}\\
            &=\EE\left\{\hpp\EE[Y|\hpp]\right\}\\
            &=\EE\left\{\hpp\left[\mu_1\hpp+\mu_0(1-\hpp)\right]\right\}\\
            &=\mu_1\EE[\hpp^2]+\mu_0\left(\EE[\hpp]-\EE[\hpp^2]\right)
\end{align*}


That gives us four parameters:
\begin{align*}
  \theta_1&=\EE[\hpp]\\
  \theta_2&=\EE[\hpp^2]\\
  \theta_3&=\mu_0\\
  \theta_4&=\mu_1
\end{align*}

and four estimating equations:
\begin{align*}
  \sum_i \hppi-\theta_1&=0\\
  \sum_i \hppi^2-\theta_2&=0\\
  \sum_i Y_i-\theta_4\theta_1-\theta_3(1-\theta_1)&=0\\
  \sum_i Y_i\hppi-\theta_4\theta_2-\theta_3(\theta_1-\theta_2)&=0
\end{align*}


\section{Relaxing \eqref{eq:assumption} with regression}
There's no particular reason to assume \eqref{eq:assumption} and it seems like it would typically be pretty implausible. 

But say you believe the model
\begin{equation}\label{eq:regression}
Y_i=\bm{x}_i'\bm{\beta}+\gamma S_i+\epsilon_i
\end{equation}
 Then instead of \eqref{eq:assumption} we could assume something like
\begin{equation*}
\EE[Y_i-\bm{x}_i'\bm{\beta}|\bm{X}_i,S_i]=\EE[Y_i-\bm{x}_i'\bm{\beta}|S_i]
\end{equation*}

in other words, no interaction between $\bm{X}$ and $S$ in \eqref{eq:assumption}. 
Then, if you had an estimate for $\beta$, you could just substitute $Y_i-\bm{x}_i'\bm{\beta}$ for $Y_i$ in the estimates. 
Alternatively, you could use a stacked estimating equation approach and estimate it all together.

\bibliographystyle{unsrtnat}
\bibliography{MOM}

\end{document}
